{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcacb12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import docx\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d42478",
   "metadata": {},
   "source": [
    "## Step 1. Import the dashbaord and keep the jobs of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b87c3b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:/workshops/temp_World Bank Jobs Application Dashboard and Automate\")\n",
    "df = pd.read_excel('wb dashboard.xlsm')\n",
    "df = df[df['status_update'].isin(['working on it','strongly interested']) ]\n",
    "data = {\n",
    "    'scope': {\n",
    "        'key': r\"\\bScope\\b\",\n",
    "        'output':''\n",
    "    },\n",
    "    \n",
    "    'duty': {\n",
    "        'key': r\"\\bDuties\\b\",\n",
    "        'output':''\n",
    "    },\n",
    "    \n",
    "    'responsibilities': {\n",
    "        'key': r\"\\bResponbilities\\b\",\n",
    "        'output':''\n",
    "    },\n",
    "    \n",
    "    \n",
    "    'criteria': {\n",
    "        'key': r\"\\bCriteria\\b\",\n",
    "        'output':''\n",
    "    },\n",
    "    \n",
    "    'suffix': {\n",
    "        'key': r\"\\bWorld Bank Group Core\\b\",\n",
    "        'output':''\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd19cf",
   "metadata": {},
   "source": [
    "## Step 2. Define a program to retrieve the job descriptions for chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab4ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_str(strname:str):\n",
    "    data[strname]['output'] = ''\n",
    "    try: \n",
    "        l = len(soup.find('p', text = re.compile(data[strname]['key'])).find_next_siblings('p'))\n",
    "        for i in range(0,l):\n",
    "            data[strname]['output'] = data[strname]['output'] + soup.find('p', text = re.compile(data[strname]['key'])).find_next_siblings('p')[i].text.strip()\n",
    "    except:\n",
    "        print(data[strname]['key'] + ' not founded in this job')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5347d0ac",
   "metadata": {},
   "source": [
    "## Step 3. Loop through the jobs you are interested and automate cover letter drafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63fe1928",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\bScope\\b not founded in this job\n",
      "\\bDuties\\b not founded in this job\n",
      "\\bResponbilities\\b not founded in this job\n",
      "\\bScope\\b not founded in this job\n",
      "\\bDuties\\b not founded in this job\n",
      "\\bResponbilities\\b not founded in this job\n",
      "\\bScope\\b not founded in this job\n",
      "\\bDuties\\b not founded in this job\n",
      "\\bResponbilities\\b not founded in this job\n",
      "\\bScope\\b not founded in this job\n",
      "\\bDuties\\b not founded in this job\n",
      "\\bResponbilities\\b not founded in this job\n",
      "\\bScope\\b not founded in this job\n",
      "\\bDuties\\b not founded in this job\n",
      "\\bResponbilities\\b not founded in this job\n",
      "\\bScope\\b not founded in this job\n",
      "\\bResponbilities\\b not founded in this job\n",
      "\\bScope\\b not founded in this job\n",
      "\\bDuties\\b not founded in this job\n",
      "\\bResponbilities\\b not founded in this job\n",
      "\\bScope\\b not founded in this job\n",
      "\\bDuties\\b not founded in this job\n",
      "\\bResponbilities\\b not founded in this job\n",
      "\\bScope\\b not founded in this job\n",
      "\\bDuties\\b not founded in this job\n",
      "\\bResponbilities\\b not founded in this job\n",
      "\\bScope\\b not founded in this job\n",
      "\\bDuties\\b not founded in this job\n",
      "\\bResponbilities\\b not founded in this job\n",
      "\\bScope\\b not founded in this job\n",
      "\\bDuties\\b not founded in this job\n",
      "\\bResponbilities\\b not founded in this job\n",
      "\\bScope\\b not founded in this job\n",
      "\\bResponbilities\\b not founded in this job\n",
      "\\bScope\\b not founded in this job\n",
      "\\bDuties\\b not founded in this job\n",
      "\\bResponbilities\\b not founded in this job\n",
      "\\bScope\\b not founded in this job\n",
      "\\bDuties\\b not founded in this job\n",
      "\\bResponbilities\\b not founded in this job\n",
      "\\bScope\\b not founded in this job\n",
      "\\bDuties\\b not founded in this job\n",
      "\\bResponbilities\\b not founded in this job\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,df.shape[0]):\n",
    "# for i in range(0,1):\n",
    "    url = requests.get(df.iloc[i]['detail']).content\n",
    "    soup = BeautifulSoup(url, 'html.parser')\n",
    "\n",
    "    for item in ['scope', 'duty', 'responsibilities', 'criteria', 'suffix']:\n",
    "        save_str(item)\n",
    "\n",
    "    ####################################\n",
    "    # Define the job description\n",
    "    job = ''\n",
    "\n",
    "    if data['responsibilities']['output'] in data['duty']['output']:\n",
    "        job = data['duty']['output']\n",
    "    else: job = data['duty']['output'] + data['responsibilities']['output']\n",
    "    if job in data['scope']['output']:\n",
    "        job = data['scope']['output']\n",
    "    else: \n",
    "        job = job + data['scope']['output']\n",
    "\n",
    "    if data['suffix']['output'] in data['criteria']['output']:\n",
    "        job = data['criteria']['output'].replace(data['suffix']['output'],\"\")\n",
    "\n",
    "    if job in data['scope']['output']:\n",
    "        job = data['scope']['output']\n",
    "    else: \n",
    "        job = data['scope']['output'] + job\n",
    "\n",
    "    missing_words = ['â€¢','\\r','\\n','\\xa0','World Bank Group Core Competencies']\n",
    "    for word in missing_words:\n",
    "        job = job.replace(word,'').strip()\n",
    "\n",
    "    ####################################\n",
    "    # Define my experience\n",
    "    with open('Sources/' + df.iloc[i]['code'] + '.txt', 'r') as file:\n",
    "        exp = file.read()\n",
    "\n",
    "    ####################################\n",
    "    # Use ChatGPT api to pre-populate the cover letter\n",
    "    title = df.iloc[i]['title']\n",
    "    instit = df.iloc[i]['instit']\n",
    "    prompt = ('Please provide a cover letter for the ' +\n",
    "        title + ' at the ' +\n",
    "        instit + ' accoring to the following job description: ' + \n",
    "        job + ' And please take my following experience into consideration: ' +\n",
    "        exp + ' The cover letter should have multiple paragraphs, have 500-550 words.')\n",
    "    prompt\n",
    "    \n",
    "    openai.api_key = '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'\n",
    "    response = openai.Completion.create(\n",
    "      engine=\"text-davinci-003\",\n",
    "      prompt=prompt,\n",
    "      max_tokens=1500\n",
    "    )\n",
    "\n",
    "    ####################################\n",
    "    # Write the output into a document template\n",
    "    doc = docx.Document('cl template.docx')\n",
    "    str_to_insert = response.choices[0].text\n",
    "    paragraphs = doc.paragraphs\n",
    "    dear_para = None\n",
    "    sincerely_para = None\n",
    "\n",
    "    for para in paragraphs:\n",
    "        if 'swang5' in para.text:\n",
    "            dear_para = para\n",
    "            dear_index = paragraphs.index(dear_para)+1\n",
    "        if 'February 06, 2023' in para.text:\n",
    "            para.text = datetime.date.today().strftime(\"%B %d, %Y\")\n",
    "    # print('dear_index',dear_index)\n",
    "    para = doc.paragraphs[dear_index]\n",
    "    new_para = doc.add_paragraph(response.choices[0].text)\n",
    "    para._element.addprevious(new_para._element)\n",
    "\n",
    "    doc.save('CV and CL by job id codes/' + df.iloc[i]['code'] + '_Shiyao Wang Cover Letter.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "60203f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.iloc[i]['code'] + ' ' + title)\n",
    "# print(prompt)\n",
    "# print(\" \")\n",
    "# print(\"############################\")\n",
    "# print(\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
